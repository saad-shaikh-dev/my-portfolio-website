{
    "componentChunkName": "component---src-templates-article-js",
    "path": "/my-articles/how-to-create-an-api-that-extracts-data-from-websites",
    "result": {"data":{"markdownRemark":{"html":"<p>Hi, I am an aspiring we developer and I am going to show you how to create an API that aggregates data from various websites.</p>\n<p>I will be using Node JS with the extensions axios, cheerio and express as well as nodemon for the development phase.</p>\n<p>So here goes..</p>\n<p>First, you make sure you have NodeJS installed. In order to do this, open a terminal and type the following command:</p>\n<pre><code>sudo apt install nodejs\n</code></pre>\n<p>This command, checks if node is already installed. If it is, then it will tell you so, otherwise it will install it.</p>\n<p>After that, you create a folder with the name of you API application. Mine is called “renewable-energy-news-api” in my desktop.</p>\n<p>Then you navigate to the folder from the terminal using the command “cd [folder-address]”. Since mine is in the desktop I typed “cd Desktop/renewable-energy-news-api”.</p>\n<p>Once you are in the newly created folder, you need to start installing some things. First, I suggest you open the project folder in your IDE of choice so you can see what’s happening.</p>\n<p>The first thing you install is the package.json file. This file contains all the relevant information about the project. You can also use this file to create some command line shortcuts which are called scripts.</p>\n<p>To install package.json, type “npm init” in the command line. As you may have noticed, I’m using the command line a lot. This is because it gets things done much faster. Anyway, once you have typed “npm init” and hit enter, you will be asked to fill up the details about the project. You can fill it up the way you want to. The only important part to fill is the “entry point”. Here you have to specify the name of the main file where all of your code will be and where all the other files will point to. Since this file does not exits yet, you can name it anything you want. I plan using the default name index.js, so I just hit enter the let the package.json file get created.</p>\n<p>Now, we need to install some extensions. The extension we are going to install are axios, cheerio, express and nodemon. Axios is used to fetch data from a source, cheerio manipulates data structures, express connects nodejs to a server and nodemon automatically refreshes the application in the local server whenever we make any change to the back end code without needing to close and restart the server.</p>\n<p>The syntax to install extensions from the command line is “npm install [extension-name]” or the shorter version “npm i [extension-name]”. You can also install multiple extensions simultaneously by leaving a space between each extension name. So I typed “npm i axios cheerio express nodemon” and hit enter, and voila, all the extensions were installed.</p>\n<p>Now, let’s create a script to start the application locally so that we can see what it looks like before it is deployed. For that, you write the below code in the scripts property of the package.json file:</p>\n<pre><code>\"start\": \"nodemon index.js\"\n</code></pre>\n<p>Alrighty, so let’s get to the meat of this project then. Now, we finally create the index.js file I was talking about before. Once you have created it, we can start coding.</p>\n<p>In the index.js file, the first thing we do is import the extension we have installed and give it a local name. The syntax for that is “const [extension-local-name] = require(“[extension-name]”). Let’s type in the below code in the file:</p>\n<pre><code>const express = require(\"express\");\nconst axios = require(\"axios\");\nconst cheerio = require(\"cheerio\");\n</code></pre>\n<p>Next, you want to add the port to which the app will be deployed to. There will be two ports. One for local hosting (I will be using 5006) and one for the actual deployment. So you add:</p>\n<pre><code>const port = process.env.PORT || 5006;\n</code></pre>\n<p>Now, you need to create a list of sources from where to get the news about renewable energy. For that, create an object called “newsSources” containing the details about these various news organizations:</p>\n<pre><code>const newsSources = [\n    {\n        name: \"telegraph\",\n        domain: \"https://www.telegraph.co.uk\",\n        url: \"https://www.telegraph.co.uk/renewable-energy/\",\n    },\n    {\n        name: \"the-guardian\",\n        domain: \"https://www.theguardian.com\",\n        url: \"https://www.theguardian.com/environment/renewableenergy\",\n    },\n    {\n        name: \"the-times\",\n        domain: \"https://www.thetimes.co.uk\",\n        url: \"https://www.thetimes.co.uk/search?source=search-page&#x26;q=renewable\",\n    },\n    {\n        name: \"al-jazeera\",\n        domain: \"https://www.aljazeera.com\",\n        url: \"https://www.aljazeera.com/search/renewable\"\n    },\n    {\n        name: \"recharge-news\",\n        domain: \"https://www.rechargenews.com\",\n        url: \"https://www.rechargenews.com/\"\n    },\n    {\n        name: \"renewables-now\",\n        domain: \"https://renewablesnow.com/news\",\n        url: \"https://renewablesnow.com/\"\n    },\n    {\n        name: \"science-daily\",\n        domain: \"https://www.sciencedaily.com\",\n        url: \"https://www.sciencedaily.com/search/?keyword=renewable#gsc.tab=0&#x26;gsc.q=renewable&#x26;gsc.page=1\"\n    },\n    {\n        name: \"renewable-energy-magazine\",\n        domain: \"https://www.renewableenergymagazine.com\",\n        url: \"https://www.renewableenergymagazine.com/search?cx=partner-pub-7794467828055047%3A8692188386&#x26;cof=FORID%3A9&#x26;ie=UTF-8&#x26;q=renewable\"\n    },\n    {\n        name: \"world-energy-news\",\n        domain: \"https://www.worldenergynews.com\",\n        url: \"https://www.worldenergynews.com/news/search?search=renewable\"\n    }\n];\n</code></pre>\n<p>After that, you create a blank array to which will then store an object that holds all the latest renewable energy related news that has been extracted from the news sources listed in the “newsSources” object. I will call it “news”:</p>\n<pre><code>const news = [];\n</code></pre>\n<p>Now, you will use express to connect to the server and create pages in the app. The default syntax to use express is “express()” but it is better to create a shorter version of the syntax for local use for faster coding. I will call the shortened form of “express()” as “app”:</p>\n<pre><code>const app = express();\n</code></pre>\n<p>There will be three page types in the app,:</p>\n<ul>\n<li>The home page — this page gives a brief description about the application.</li>\n<li>The news page — this page contains all the news about renewable energy from the various news sources.</li>\n<li>The news pages from individual sources — these pages will contain renewable energy related news from the individual sources.</li>\n</ul>\n<p>We will create each page using a get request in express and then displaying the contents of the page in json format.</p>\n<p>First, let’s create the home page. Mine will be a simple page that briefly describes the purpose of the site and provides a link to the news page. Obviously, you use the address “/” for this page. As you can see below, the link I entered is to the actual deployed app. However, since It does not exist yet for you, you can use the link “<a href=\"http://localhost:5006/news%E2%80%9D\">http://localhost:5006/news”</a> instead.</p>\n<pre><code>app.get(\"/\", (action, reaction) => {\n    reaction.json(`Hi, my name is Saad Shaikh and this is the climate change news API. Go to the link 'https://climate-change-feed-api.herokuapp.com/news' to get your news updates`);\n});\n</code></pre>\n<p>Next, you need to create the news page. This is the most important page in the application. I will use the address “/news” for this page but you can name it whatever you want. First, you create a get request with the address “/news” (or anything else that you prefer). Then, you use the Javascript map function on the “newsSources” object to map through the verious news organisations and name each individual one “newsSource” (in case you can’t see it, it does not have an “s”). After that, you will use axios to connect to the urls in those news sources. These are the steps for using axios:</p>\n<ul>\n<li>Use the “get” request in axios to extract the website url of the individual news source from the “url” property in the object.</li>\n<li>Use the “then” function to use the cheerio extension to extract all the links containing the word “renewable” and using its text and links to be added to the “news” array. You will also need to add a function to add the domain name to any of the links that just start with “/”.</li>\n<li>Use the “catch” function to log any errors.</li>\n</ul>\n<p>Lastly, you convert the now filled up “news” array of object into JSON.</p>\n<pre><code>app.get(\"/news\", (action, reaction) => {\n    newsSources.map(newsSource =>\n        axios\n            .get(newsSource.url)\n            .then(response => {\n                const html = response.data;\n                const $ = cheerio.load(html);\n                $('a:contains(\"renewable\")', html).each(function () {\n                    const title = $(this).text();\n                    const url = $(this).attr(\"href\");\n                    const link = () => url.startsWith(\"/\") ? newsSource.domain + url : url\n                    news.push({ title, url: link(), source: newsSource.name });\n                });\n            })\n            .catch(err => console.log(err))\n    );\n    reaction.json(news);\n});\n</code></pre>\n<p>The last page request that is left to create now are the news pages from individual news sources. It is similar to the previous express request but you will also need to create separate Ids for each page and use the “params” function to get the data only from the individual sources.</p>\n<pre><code>app.get(\"/news/:newsSourceId\", (req, res) => {\n    const newsSourceId = req.params.newsSourceId;\n    const newsSourceAddress = newsSources.filter(\n        newsSource => newsSource.name == newsSourceId\n    )[0].url;\n    axios\n        .get(newsSourceAddress)\n        .then(response => {\n            const html = response.data;\n            const $ = cheerio.load(html);\n            const specificArticles = [];\n            $('a:contains(\"renewable\")', html).each(function () {\n                const title = $(this).text();\n                const url = $(this).attr(\"href\");\n                /*   const link = () => url.startsWith(\"/\") ? newsSourceAddress.domain + url : url */\n                specificArticles.push({ title, url, source: newsSourceId });\n            });\n            res.json(specificArticles)\n\n        })\n        .catch(err => console.log(err));\n});\n</code></pre>\n<p>Yay! you’ve created all the pages.</p>\n<p>Finally, the last piece of code you need to write is an express function to listen to all the above code and connect it to the actual ports that were shown in the beginning. This is how you do it:</p>\n<pre><code>app.listen(port, () => console.log(`server running on port ${port}`));\n</code></pre>\n<p>Now let’s test if everything is working properly. Just type “npm start” in the terminal in your IDE (remember the script we had created?) and you application will open in “<a href=\"http://localhost:5006/%E2%80%9D\">http://localhost:5006/”</a>. Go through the app to see if everything functions as intended. If it does, then we’re done.</p>\n<p>And that’s it. You have created an API that gets news related to renewable energy from various sources. Congratulations :).</p>\n<p>Now you are free to deploy your application to the hosting provider of your choice. I will write another article in the future on how to deploy applications to various hosting providers.</p>\n<p>Till then, take care.</p>","frontmatter":{"title":"How to create an API that extracts data from websites","date":"2021.10.22","sourceCode":"https://gitlab.com/saad.shaikh/renewable-energy-news-api","projectLink":"https://renewable-energy-news-api.herokuapp.com/"}}},"pageContext":{"slug":"how-to-create-an-api-that-extracts-data-from-websites"}},
    "staticQueryHashes": []}